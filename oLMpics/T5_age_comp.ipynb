{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b886ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93cf5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"roberta-base\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=1,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f88579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb1ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        questions = [question.replace('[MASK]','<extra_id_0>') for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2c25dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/31/2021 10:51:55: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "05/31/2021 10:51:55: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db97be58a064734ba62921e9b194f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/31/2021 10:51:55: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf04ef9cbdd415b9a08af4119fb19ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args.model_name_or_path = \"t5-large\" # \"bert-large-uncased-whole-word-masking\"  # \"roberta-large\"\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.T5ForConditionalGeneration.from_pretrained(\"t5-large\").cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "train_dataset = RoBERTaDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "eval_dataset = RoBERTaDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b973cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"A 41 year old person age is <extra_id_0> than a 42 year old person.\", add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(\"<extra_id_0> older <extra_id_1> </s>\", add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "outputs = model(input_ids=input_ids.cuda(), labels=labels.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf76f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids=input_ids.cuda(), decoder_input_ids=input_ids.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44de239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11460]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOUNG_ID = tokenizer(\"blank\", add_special_tokens=False).input_ids\n",
    "YOUNG_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57971513",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c48a7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-17.3360, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, 1, YOUNG_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dd773a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    YOUNG_ID = tokenizer.encode(\" younger\", add_special_tokens=False)\n",
    "    OLD_ID = tokenizer.encode(\" older\", add_special_tokens=False)\n",
    "    YEAR_ID = tokenizer.encode(\" year\", add_special_tokens=False)\n",
    "    assert len(YOUNG_ID) == 1 and len(OLD_ID) == 1 and len(YEAR_ID) == 1\n",
    "    YOUNG_ID = YOUNG_ID[0]\n",
    "    OLD_ID = OLD_ID[0]\n",
    "    YEAR_ID = YEAR_ID[0]\n",
    "    LABELS = tokenizer(\"<extra_id_0> blank <extra_id_1> </s>\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "    LABELS = LABELS.input_ids.cuda()  # from testing, \"blank\" can be any word and results are the same\n",
    "    \n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        \n",
    "        YEAR_INDEX1 = batch[\"input_ids\"].index(YEAR_ID)\n",
    "        YEAR_INDEX2 = batch[\"input_ids\"].index(YEAR_ID, YEAR_INDEX1+1)\n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][YEAR_INDEX1-1])\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][YEAR_INDEX2-1])\n",
    "        # print(age1, age2)\n",
    "        \n",
    "        first_age.append(age1)\n",
    "        second_age.append(age2)\n",
    "                \n",
    "        del batch[\"choice_list\"] \n",
    "        del batch[\"answer_id\"] \n",
    "        for key in batch:\n",
    "            batch[key] = torch.stack(batch[key], dim=-1).cuda()\n",
    "  \n",
    "        outputs = model(input_ids=batch[\"input_ids\"], labels=LABELS)\n",
    "        logits = outputs.logits\n",
    "        if logits[0, 1, YOUNG_ID] < logits[0, 1, OLD_ID]:\n",
    "            all_preds.append(1)\n",
    "        else:\n",
    "            all_preds.append(0)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model.generate(input_ids=batch[\"input_ids\"], \n",
    "#                           num_beams=200, num_return_sequences=20,\n",
    "#                           max_length=5)\n",
    "            \n",
    "#             match = False\n",
    "#             for seq in outputs:\n",
    "#                 if YOUNG_ID in seq:\n",
    "#                     all_preds.append(0)\n",
    "#                     match = True\n",
    "#                     break\n",
    "#                 elif OLD_ID in seq:\n",
    "#                     all_preds.append(1)\n",
    "#                     match = True\n",
    "#                     break\n",
    "            \n",
    "#             if not match:\n",
    "#                 all_preds.append(-1)\n",
    "        \n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56615127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/31/2021 11:05:04: ***** Running evaluation  *****\n",
      "05/31/2021 11:05:04:   Num examples = 500\n",
      "05/31/2021 11:05:04:   Batch size = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfc7e96bdb54fc5a628329d11e369b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8cb7c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison {args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "plt.savefig(f\"imgs/{args.model_name_or_path.rsplit('/', 1)[-1]}-ages-double-nongen.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30facde6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
