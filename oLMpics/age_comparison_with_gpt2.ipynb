{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e163e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    \"\"\" Reads jsonl file (download links in readme) \"\"\"\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):  # Only difference is that BERTDataset has token_type_ids while RoBERTaDataset doesn't\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "            questions = [question.replace('[MASK]','<mask>') for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cb210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(input_ids, logits):\n",
    "    # Multiplies together individual probabilities to get overall sentence probability\n",
    "    logits = torch.nn.functional.softmax(logits, dim=2)\n",
    "    probs = torch.gather(logits, 2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    probs = probs * 1e4  # product is zero otherwise\n",
    "    probs = torch.prod(probs, dim=1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    \"\"\" \n",
    "    Evaluates model on the dataset, is currently hardcoded to only work for the Age Comparison task \n",
    "    `huggingface_generic_task.ipynb` works for all tasks but does not support GPT2\n",
    "    \"\"\"\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    YOUNG_ID = tokenizer.encode(\" younger\", add_special_tokens=False)\n",
    "    OLD_ID = tokenizer.encode(\" older\", add_special_tokens=False)\n",
    "    assert len(YOUNG_ID) == 1 and len(OLD_ID) == 1\n",
    "    YOUNG_ID = YOUNG_ID[0]\n",
    "    OLD_ID = OLD_ID[0]\n",
    "    MASK_INDEX = 8  # Hardcoded\n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    c = 0\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        for i in range(len(batch[\"answer_id\"])):\n",
    "            if batch[\"choice_list\"][0][i] == \"older\":\n",
    "                batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "        all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][:, 1 if \"gpt\" in args.model_name_or_path.lower() else 2]).split(\" \")\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][:, 13 if \"gpt\" in args.model_name_or_path.lower() else 11]).split(\" \")\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"gpt\")):\n",
    "            age1 = age1[1:]\n",
    "            age2 = age2[1:]\n",
    "        \n",
    "        first_age.extend(age1)\n",
    "        second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(batch[\"input_ids\"])):\n",
    "                batch[\"input_ids\"][i, MASK_INDEX] = YOUNG_ID\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            young_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
    "            \n",
    "            for i in range(len(batch[\"input_ids\"])):\n",
    "                batch[\"input_ids\"][i, MASK_INDEX] = OLD_ID\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            old_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
    "        \n",
    "        preds = torch.gt(old_prob, young_prob)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        \n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_answers, all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "            \n",
    "# \"bert-base-uncased\", \n",
    "# \"bert-large-uncased-whole-word-masking\", \n",
    "# \"roberta-large\",\n",
    "# \"distilbert-base-uncased\", \n",
    "# \"facebook/bart-large\",\n",
    "# \"albert-large-v1\",\n",
    "# \"google/electra-large-discriminator\",\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"gpt2\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinzhao/Documents/.oLMpics_venv/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:758: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "07/04/2021 23:05:36: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "07/04/2021 23:05:36: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a72eb0725648c3afa90ad49197dc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2021 23:05:36: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cba1b619b8e4d17bfb0f16279e2e4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.AutoModelWithLMHead.from_pretrained(args.model_name_or_path).cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\", \"gpt\")) else BERTDataset\n",
    "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6e8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2021 23:06:27: ***** Running evaluation  *****\n",
      "07/04/2021 23:06:27:   Num examples = 500\n",
      "07/04/2021 23:06:27:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98800154485f47d183be10d77b16bb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_answers, all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison\\n{args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "#plt.savefig(f\"imgs/{args.model_name_or_path.rsplit('/', 1)[-1]}-ages-double.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8480604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
