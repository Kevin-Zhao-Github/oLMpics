{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e163e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "426c1175",
   "metadata": {},
   "source": [
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--seed\",\n",
    "        default=123,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_or_path\",\n",
    "        default=\"roberta-base\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_seq_length\",\n",
    "        default=256,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_train_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        default=2,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_train_epochs\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        default=1e-5,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\",\n",
    "        default=0.1,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--warmup_ratio\",\n",
    "        default=0.06,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_cache\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_train\",\n",
    "        default=200,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_eval\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_choices\",\n",
    "        default=2,\n",
    "        type=int,\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "            questions = [question.replace('[MASK]','<mask>') for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29cb210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(input_ids, logits):\n",
    "    logits = torch.nn.functional.softmax(logits, dim=2)\n",
    "    logits = logits * 10  # 10 is arbitrary, but roughly keeps the final probability around 30 (instead of a tiny float)\n",
    "    print(input_ids.size())\n",
    "    print(logits.size())\n",
    "    probs = torch.gather(logits, 2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    probs2 = torch.zeros_like(input_ids, dtype=float)\n",
    "    for batch_ind, logit in enumerate(logits):\n",
    "        batch_input_ids = input_ids[batch_ind]\n",
    "        for seq_ind, wid in enumerate(batch_input_ids):\n",
    "            probs2[batch_ind, seq_ind] = logits[batch_ind, seq_ind, wid]\n",
    "    \n",
    "    assert torch.all(probs == probs2)\n",
    "    probs = torch.prod(probs, dim=1)\n",
    "    \n",
    "    print(probs)\n",
    "    print(torch.sum(logits[0][0]))\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    YOUNG_ID = tokenizer.encode(\" younger\", add_special_tokens=False)\n",
    "    OLD_ID = tokenizer.encode(\" older\", add_special_tokens=False)\n",
    "    assert len(YOUNG_ID) == 1 and len(OLD_ID) == 1\n",
    "    YOUNG_ID = YOUNG_ID[0]\n",
    "    OLD_ID = OLD_ID[0]\n",
    "    MASK_INDEX = 8  # Hardcoded\n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    c = 0\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        for i in range(len(batch[\"answer_id\"])):\n",
    "            if batch[\"choice_list\"][0][i] == \"older\":\n",
    "                batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "        all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][:, 2]).split(\" \")\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][:, 11]).split(\" \")\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "            age1 = age1[1:]\n",
    "            age2 = age2[1:]\n",
    "        \n",
    "        first_age.extend(age1)\n",
    "        second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            get_sentence_prob(batch[\"input_ids\"], logits)\n",
    "        \n",
    "        preds = torch.gt(logits[:, MASK_INDEX, OLD_ID], logits[:, MASK_INDEX, YOUNG_ID])\n",
    "        all_preds.extend(preds.tolist())\n",
    "        \n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_answers, all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "            \n",
    "# \"bert-base-uncased\", \n",
    "# \"bert-large-uncased-whole-word-masking\", \n",
    "# \"roberta-large\",\n",
    "# \"distilbert-base-uncased\", \n",
    "# \"facebook/bart-large\",\n",
    "# \"albert-large-v1\",\n",
    "# \"google/electra-large-discriminator\",\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"roberta-large\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2021 20:59:21: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "05/02/2021 20:59:21: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd58531fab93414287e45e3693f13b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2021 20:59:21: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1529bccbfa45c586b2282b5390e38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path).cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\")) else BERTDataset\n",
    "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b6e8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2021 22:07:22: ***** Running evaluation  *****\n",
      "05/02/2021 22:07:22:   Num examples = 500\n",
      "05/02/2021 22:07:22:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966b29d67d9440e39ffab9b5106cbb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 17])\n",
      "torch.Size([8, 17, 50265])\n",
      "tensor([38.7222, 33.3269, 34.6764, 29.4936, 26.0014, 29.9269, 30.2467, 32.1743],\n",
      "       device='cuda:0')\n",
      "tensor(10.0000, device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-01679d14dc7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# correct = [1 if all_answers[i] == all_preds[i] else 0 for i in range(len(all_answers))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(np.array(correct))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-7a065d2f0d6f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(args, model, tokenizer, eval_dataset)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mget_sentence_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASK_INDEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOLD_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASK_INDEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYOUNG_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-381a8368fd2d>\u001b[0m in \u001b[0;36mget_sentence_prob\u001b[0;34m(input_ids, logits)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_answers, all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)\n",
    "# correct = [1 if all_answers[i] == all_preds[i] else 0 for i in range(len(all_answers))]\n",
    "# print(np.array(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison\\n{args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "plt.savefig(f\"imgs/{args.model_name_or_path.rsplit('/', 1)[-1]}-ages-fixed.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59158570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<s>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85141f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6]],\n",
       "\n",
       "        [[11, 12],\n",
       "         [13, 14],\n",
       "         [15, 16]],\n",
       "\n",
       "        [[21, 22],\n",
       "         [23, 24],\n",
       "         [25, 26]],\n",
       "\n",
       "        [[31, 32],\n",
       "         [33, 34],\n",
       "         [35, 36]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = torch.tensor([[[1, 2], [3, 4], [5, 6]], [[11, 12], [13, 14], [15, 16]], [[21, 22], [23, 24], [25, 26]], [[31, 32], [33, 34], [35, 36]]])\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa6f2f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1],\n",
       "         [ 4],\n",
       "         [ 5]],\n",
       "\n",
       "        [[11],\n",
       "         [13],\n",
       "         [15]],\n",
       "\n",
       "        [[21],\n",
       "         [23],\n",
       "         [25]],\n",
       "\n",
       "        [[31],\n",
       "         [33],\n",
       "         [35]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = torch.tensor([[[0], [1], [0]], [[0], [0], [0]], [[0], [0], [0]], [[0], [0], [0]]])\n",
    "torch.gather(asdf, 2, inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8480604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
