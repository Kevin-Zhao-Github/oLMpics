{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e163e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "426c1175",
   "metadata": {},
   "source": [
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--seed\",\n",
    "        default=123,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_or_path\",\n",
    "        default=\"roberta-base\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_seq_length\",\n",
    "        default=256,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_train_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        default=2,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_train_epochs\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        default=1e-5,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\",\n",
    "        default=0.1,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--warmup_ratio\",\n",
    "        default=0.06,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_cache\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_train\",\n",
    "        default=200,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_eval\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_choices\",\n",
    "        default=2,\n",
    "        type=int,\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"roberta-base\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        questions = [question.replace('[MASK]','<mask>') for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    YOUNG_ID = tokenizer.encode(\" younger\", add_special_tokens=False)\n",
    "    OLD_ID = tokenizer.encode(\" older\", add_special_tokens=False)\n",
    "    assert len(YOUNG_ID) == 1 and len(OLD_ID) == 1\n",
    "    YOUNG_ID = YOUNG_ID[0]\n",
    "    OLD_ID = OLD_ID[0]\n",
    "    MASK_INDEX = 8  # Hardcoded\n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    c = 0\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        for i in range(len(batch[\"answer_id\"])):\n",
    "            if batch[\"choice_list\"][0][i] == \"older\":\n",
    "                batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "        all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][:, 2]).split(\" \")\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][:, 11]).split(\" \")\n",
    "        \n",
    "        if \"roberta\" in args.model_name_or_path:\n",
    "            batch[\"token_type_ids\"] = None\n",
    "            age1 = age1[1:]\n",
    "            age2 = age2[1:]\n",
    "        \n",
    "        first_age.extend(age1)\n",
    "        second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        preds = torch.gt(logits[:, MASK_INDEX, OLD_ID], logits[:, MASK_INDEX, YOUNG_ID])\n",
    "        all_preds.extend(preds.tolist())\n",
    "        \n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_answers, all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "04/24/2021 10:00:28: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "04/24/2021 10:00:28: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cc4ecaa6d145689c5139c1ee64ead9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/24/2021 10:00:28: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7996061165884e66a2c0203539a3aa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args.model_name_or_path = \"bert-large-uncased-whole-word-masking\"  # \"roberta-large\"\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path).cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "AgeDataset = RoBERTaDataset if \"roberta\" in tokenizer.name_or_path else BERTDataset\n",
    "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b6e8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/24/2021 10:00:35: ***** Running evaluation  *****\n",
      "04/24/2021 10:00:35:   Num examples = 500\n",
      "04/24/2021 10:00:35:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b974f402454bb984376f3608024bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_answers, all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)\n",
    "# correct = [1 if all_answers[i] == all_preds[i] else 0 for i in range(len(all_answers))]\n",
    "# print(np.array(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329b0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ef19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison {args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "plt.savefig(f\"imgs/{args.model_name_or_path}-ages-fixed.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5549e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
