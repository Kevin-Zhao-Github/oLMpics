{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e163e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "426c1175",
   "metadata": {},
   "source": [
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--seed\",\n",
    "        default=123,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_or_path\",\n",
    "        default=\"roberta-base\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_seq_length\",\n",
    "        default=256,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_train_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--per_device_eval_batch_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        default=2,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_train_epochs\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        default=1e-5,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--weight_decay\",\n",
    "        default=0.1,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--warmup_ratio\",\n",
    "        default=0.06,\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_cache\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_train\",\n",
    "        default=200,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_eval\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_choices\",\n",
    "        default=2,\n",
    "        type=int,\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "            questions = [question.replace('[MASK]','<mask>') for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29cb210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(input_ids, logits):\n",
    "    #print(\"--\")\n",
    "    #print(logits)\n",
    "    if torch.min(logits) < 0:\n",
    "        logits = logits - torch.min(logits) + 1e-10\n",
    "    #logits = torch.nn.functional.softmax(logits, dim=2)\n",
    "    #print(logits)\n",
    "    probs = torch.gather(logits, 2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "#     probs2 = torch.zeros_like(input_ids, dtype=float)\n",
    "#     for batch_ind, logit in enumerate(logits):\n",
    "#         batch_input_ids = input_ids[batch_ind]\n",
    "#         for seq_ind, wid in enumerate(batch_input_ids):\n",
    "#             probs2[batch_ind, seq_ind] = logits[batch_ind, seq_ind, wid]\n",
    "    \n",
    "#     assert torch.all(probs == probs2)\n",
    "    probs = torch.prod(probs, dim=1)\n",
    "    #print(probs)\n",
    "    #assert False\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    YOUNG_ID = tokenizer.encode(\" younger\", add_special_tokens=False)\n",
    "    OLD_ID = tokenizer.encode(\" older\", add_special_tokens=False)\n",
    "    assert len(YOUNG_ID) == 1 and len(OLD_ID) == 1\n",
    "    YOUNG_ID = YOUNG_ID[0]\n",
    "    OLD_ID = OLD_ID[0]\n",
    "    MASK_INDEX = 8  # Hardcoded\n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    c = 0\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        for i in range(len(batch[\"answer_id\"])):\n",
    "            if batch[\"choice_list\"][0][i] == \"older\":\n",
    "                batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "        all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][:, 2]).split(\" \")\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][:, 11]).split(\" \")\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "            age1 = age1[1:]\n",
    "            age2 = age2[1:]\n",
    "        \n",
    "        first_age.extend(age1)\n",
    "        second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(batch[\"input_ids\"])):\n",
    "                batch[\"input_ids\"][i, MASK_INDEX] = YOUNG_ID\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            young_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
    "            \n",
    "            for i in range(len(batch[\"input_ids\"])):\n",
    "                batch[\"input_ids\"][i, MASK_INDEX] = OLD_ID\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            old_prob = get_sentence_prob(batch[\"input_ids\"], logits)\n",
    "        \n",
    "        # preds = torch.gt(logits[:, MASK_INDEX, OLD_ID], logits[:, MASK_INDEX, YOUNG_ID])\n",
    "        preds = torch.gt(old_prob, young_prob)\n",
    "        #print(\"---\")\n",
    "        #print(preds)\n",
    "        #print(young_prob)\n",
    "        #print(old_prob)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        \n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_answers, all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "            \n",
    "# \"bert-base-uncased\", \n",
    "# \"bert-large-uncased-whole-word-masking\", \n",
    "# \"roberta-large\",\n",
    "# \"distilbert-base-uncased\", \n",
    "# \"facebook/bart-large\",\n",
    "# \"albert-large-v1\",\n",
    "# \"google/electra-large-discriminator\",\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"facebook/bart-large\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/03/2021 21:50:50: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "05/03/2021 21:50:50: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf10993e1d1c4d37a364b4105a88e78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/03/2021 21:50:50: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea8825aa4d74b519eddba5dc8b76ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.AutoModelWithLMHead.from_pretrained(args.model_name_or_path).cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\")) else BERTDataset\n",
    "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b6e8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/03/2021 21:50:50: ***** Running evaluation  *****\n",
      "05/03/2021 21:50:50:   Num examples = 500\n",
      "05/03/2021 21:50:50:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bb7f93adf6486fa8f8482c4ed9b36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_answers, all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)\n",
    "# correct = [1 if all_answers[i] == all_preds[i] else 0 for i in range(len(all_answers))]\n",
    "# print(np.array(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ef19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison\\n{args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "plt.savefig(f\"imgs/{args.model_name_or_path.rsplit('/', 1)[-1]}-ages-double.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59158570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<s>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85141f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6]],\n",
       "\n",
       "        [[11, 12],\n",
       "         [13, 14],\n",
       "         [15, 16]],\n",
       "\n",
       "        [[21, 22],\n",
       "         [23, 24],\n",
       "         [25, 26]],\n",
       "\n",
       "        [[31, 32],\n",
       "         [33, 34],\n",
       "         [35, 36]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = torch.tensor([[[1, 2], [3, 4], [5, 6]], [[11, 12], [13, 14], [15, 16]], [[21, 22], [23, 24], [25, 26]], [[31, 32], [33, 34], [35, 36]]])\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa6f2f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1],\n",
       "         [ 4],\n",
       "         [ 5]],\n",
       "\n",
       "        [[11],\n",
       "         [13],\n",
       "         [15]],\n",
       "\n",
       "        [[21],\n",
       "         [23],\n",
       "         [25]],\n",
       "\n",
       "        [[31],\n",
       "         [33],\n",
       "         [35]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = torch.tensor([[[0], [1], [0]], [[0], [0], [0]], [[0], [0], [0]], [[0], [0], [0]]])\n",
    "torch.gather(asdf, 2, inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8480604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
