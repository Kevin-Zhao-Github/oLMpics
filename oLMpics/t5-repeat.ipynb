{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d009a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"roberta-base\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions, max_length=25, padding=\"max_length\")\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "#         if \"t5\" in tokenizer.name_or_path.lower():\n",
    "#             questions = [question.replace('[MASK]', '') for question in questions]\n",
    "#         else:\n",
    "        questions = [question.replace('[MASK]', tokenizer.mask_token) for question in questions]\n",
    "        out = tokenizer(questions, max_length=25, padding=\"max_length\")\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    print(tokenizer.mask_token)\n",
    "    MASK_ID = tokenizer.encode(tokenizer.mask_token, add_special_tokens=False)\n",
    "    assert len(MASK_ID) == 1\n",
    "    MASK_ID = MASK_ID[0]\n",
    "#     if \"t5\" in args.model_name_or_path.lower():\n",
    "# #         LABELS = tokenizer(\"<extra_id_0>\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "#         LABELS = tokenizer(\"<extra_id_0> potato <extra_id_1> </s>\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "#         LABELS = LABELS.input_ids#.cuda() \n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    all_attentions = torch.zeros((model.config.num_hidden_layers, model.config.num_attention_heads))  # (24, 16) for BERT-large\n",
    "    \n",
    "    head_mask = torch.ones(model.config.num_hidden_layers, model.config.num_attention_heads)\n",
    "    \n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        # batch[\"choice_list\"] is [num_choices, batch_size]\n",
    "        for i in range(len(batch[\"choice_list\"][0])):\n",
    "            all_answers.append(batch[\"choice_list\"][batch[\"answer_id\"][i]][i])\n",
    "        \n",
    "        choice_lists = batch.pop(\"choice_list\")\n",
    "        batch_len = len(batch[\"answer_id\"])\n",
    "        del batch[\"answer_id\"] \n",
    "        for key in batch:\n",
    "            batch[key] = torch.stack(batch[key], dim=-1)#.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #if \"gpt\" not in args.model_name_or_path.lower():\n",
    "            if \"t5\" not in args.model_name_or_path.lower():\n",
    "                outputs = model(**batch, output_attentions=True, head_mask=head_mask)\n",
    "            else:\n",
    "                outputs = model(input_ids=batch[\"input_ids\"], decoder_input_ids=torch.zeros((len(batch[\"input_ids\"]), 1), dtype=torch.int))\n",
    "#                 outputs = model(input_ids=batch[\"input_ids\"], decoder_input_ids=batch[\"input_ids\"])\n",
    "#                 BATCH_LABELS = LABELS.repeat(batch_len, 1)\n",
    "#                 outputs = model(input_ids=batch[\"input_ids\"], labels=BATCH_LABELS)\n",
    "            \n",
    "#             attentions = torch.stack(outputs.attentions) #[:,:,:,:-1, :-1]\n",
    "            \n",
    "#             for b in range(attentions.size()[1]):\n",
    "#                 #sep_ind = (batch[\"input_ids\"][b] == tokenizer.encode(tokenizer.sep_token, add_special_tokens=False)[0]).nonzero(as_tuple=True)[0].item()\n",
    "#                 sep_ind = (batch[\"input_ids\"][b] == tokenizer.encode(tokenizer.sep_token, add_special_tokens=False)[0]).nonzero(as_tuple=True)[0].item()\n",
    "#                 for seq_ind1 in range(attentions.size()[-1]):\n",
    "#                     for seq_ind2 in range(attentions.size()[-1]):\n",
    "#                         if seq_ind1 == sep_ind or seq_ind2 == sep_ind or seq_ind1 == 0 or seq_ind2 == 0:\n",
    "#                             attentions[:, b, :, seq_ind1, seq_ind2] = 0\n",
    "            \n",
    "#             maxes = torch.amax(attentions, dim=(3, 4))\n",
    "#             sums = torch.sum(maxes, dim=1)\n",
    "#             torch.add(all_attentions, sums, out=all_attentions)\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            print(logits.size())\n",
    "            choice_ids = []\n",
    "            \n",
    "            for i, logit in enumerate(logits):  # Assuming all are single tokens\n",
    "                choice_ids = torch.tensor([tokenizer.encode(\" \" + choice_lists[j][i], add_special_tokens=False)[0] for j in range(len(choice_lists))])\n",
    "#                 print(choice_ids)\n",
    "                if \"t5\" in args.model_name_or_path.lower():\n",
    "#                     probs = logit[0].index_select(0, choice_ids)#.cuda()\n",
    "                    probs = logit[0].index_select(0, choice_ids)#.cuda()\n",
    "#                     print(probs)\n",
    "                else:\n",
    "                    MASK_INDEX = batch[\"input_ids\"][i].tolist().index(MASK_ID) \n",
    "                    probs = logit[MASK_INDEX].index_select(0, choice_ids)#.cuda())\n",
    "                \n",
    "                max_ind = torch.argmax(probs)\n",
    "                all_preds.append(choice_lists[max_ind][i])\n",
    "\n",
    "    torch.div(all_attentions, len(eval_dataloader) * args.per_device_eval_batch_size, out=all_attentions)\n",
    "    return all_answers, all_preds, all_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-704f3de70fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     args.per_device_eval_batch_size = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<extra_id_0>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;34m\"gpt\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.oLMpics_venv/lib/python3.9/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__version__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2487\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2489\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.oLMpics_venv/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.oLMpics_venv/lib/python3.9/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.oLMpics_venv/lib/python3.9/site-packages/transformers/models/auto/__init__.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/Documents/.oLMpics_venv/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sentencepiece_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_bart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_japanese\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_bert_japanese\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertJapaneseTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_fill_cache\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "'''\n",
    "\"bert-base-uncased\"\n",
    "\"distilbert-base-uncased\"\n",
    "\"bert-large-uncased\"\n",
    "\"bert-large-uncased-whole-word-masking\" \n",
    "\"roberta-large\"\n",
    "\"facebook/bart-large\"\n",
    "\"t5-large\"\n",
    "\"albert-large-v1\"\n",
    "'''\n",
    "\n",
    "args.model_name_or_path = \"t5-large\"\n",
    "transformers.set_seed(args.seed)\n",
    "if \"t5\" in args.model_name_or_path.lower():\n",
    "    model = transformers.T5ForConditionalGeneration.from_pretrained(args.model_name_or_path)#.cuda()\n",
    "#     args.per_device_eval_batch_size = 1\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.mask_token = \"<extra_id_0>\"\n",
    "elif \"gpt\" in args.model_name_or_path.lower():\n",
    "    model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path)#.cuda()\n",
    "    args.per_device_eval_batch_size = 1\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.mask_token = \"[MASK]\"\n",
    "else:\n",
    "    model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path)#.cuda()\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8da753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (6): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (7): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (8): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (10): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (11): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (12): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (13): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (14): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (15): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (16): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (17): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (18): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (19): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (20): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (21): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (22): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (23): T5Block(\n",
       "    (layer): ModuleList(\n",
       "      (0): T5LayerSelfAttention(\n",
       "        (SelfAttention): T5Attention(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): T5LayerFF(\n",
       "        (DenseReluDense): T5DenseReluDense(\n",
       "          (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57925868",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, model.config.num_layers):\n",
    "    model.encoder.block[i] = model.encoder.block[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b1d595d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0168,  0.0388,  0.0312,  ...,  0.0302, -0.0036, -0.0067],\n",
       "        [ 0.0136,  0.0199,  0.0136,  ...,  0.0464,  0.0172,  0.0315],\n",
       "        [ 0.0084,  0.0007,  0.0025,  ..., -0.0500, -0.0018,  0.0039],\n",
       "        ...,\n",
       "        [ 0.0270, -0.0004, -0.0171,  ...,  0.0078, -0.0005, -0.0009],\n",
       "        [-0.0159,  0.0104, -0.0110,  ..., -0.0173, -0.0422,  0.0272],\n",
       "        [ 0.0054, -0.0069, -0.0070,  ...,  0.0013, -0.0332, -0.0007]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block[4].layer[0].SelfAttention.q.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08022966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0168,  0.0388,  0.0312,  ...,  0.0302, -0.0036, -0.0067],\n",
       "        [ 0.0136,  0.0199,  0.0136,  ...,  0.0464,  0.0172,  0.0315],\n",
       "        [ 0.0084,  0.0007,  0.0025,  ..., -0.0500, -0.0018,  0.0039],\n",
       "        ...,\n",
       "        [ 0.0270, -0.0004, -0.0171,  ...,  0.0078, -0.0005, -0.0009],\n",
       "        [-0.0159,  0.0104, -0.0110,  ..., -0.0173, -0.0422,  0.0272],\n",
       "        [ 0.0054, -0.0069, -0.0070,  ...,  0.0013, -0.0332, -0.0007]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.block[15].layer[0].SelfAttention.q.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca81746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/10/2021 12:55:49: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n",
      "10/10/2021 12:55:49: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c9ab0b1e1f49a7a69cf89a4418ca99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/10/2021 12:55:49: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79240f735eb4588a49afd48a7926c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "\"data/number_comparison_age_compare_masked_dev.jsonl\"\n",
    "\"data/coffee_cats_quantifiers_dev.jsonl\"\n",
    "\"data/size_comparison_dev.jsonl\"\n",
    "\"data/antonym_synonym_negation_dev.jsonl\"\n",
    "\"data/hypernym_conjunction_dev.jsonl\"\n",
    "'''\n",
    "train_path = \"data/number_comparison_age_compare_masked_dev.jsonl\"\n",
    "# train_path = \"data/number_comparison_age_compare_masked_train.jsonl\"\n",
    "# train_path = \"data/size_comparison_dev.jsonl\"\n",
    "# train_path = \"data/coffee_cats_quantifiers_dev.jsonl\"\n",
    "args.num_choices = 2\n",
    "eval_path = train_path #\"data/coffee_cats_quantifiers_dev.jsonl\"\n",
    "train_questions, train_choices, train_answer_ids = get_data(train_path, args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(eval_path, args.sample_eval, args.num_choices)\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\", \"electra\", \"t5\")) else BERTDataset\n",
    "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer)\n",
    "eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer)\n",
    "# eval_dataset = AgeDataset(eval_questions[:500], eval_choices[:500], eval_answer_ids[:500], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b6e8937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/10/2021 17:31:05: ***** Running evaluation  *****\n",
      "10/10/2021 17:31:05:   Num examples = 500\n",
      "10/10/2021 17:31:05:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef90c9e1d4e745cdaefb13f4173c6818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0>\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([8, 1, 32128])\n",
      "torch.Size([4, 1, 32128])\n",
      "0.494\n"
     ]
    }
   ],
   "source": [
    "all_answers, all_preds, all_attentions = evaluate(args, model, tokenizer, eval_dataset)\n",
    "# 0.956 t5 normal\n",
    "print((np.array(all_answers) == np.array(all_preds)).mean())  # t5albert all - 0.492, t5normal=0.494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290412b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
