{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e163e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer, replacement):\n",
    "        questions = [question.replace(\"[MASK]\", replacement) for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer, replacement):\n",
    "        # if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "        #     questions = [question.replace('[MASK]','<mask>') for question in questions]\n",
    "        questions = [question.replace(\"[MASK]\", replacement) for question in questions]\n",
    "        out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "CombinedDataset = namedtuple(\"CombinedDataset\", \"young_dataset, old_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cb210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(model_name, input_ids, logits):\n",
    "    #print(\"--\")\n",
    "    #print(logits)\n",
    "#     if torch.min(logits) < 0:\n",
    "#         logits = logits - torch.min(logits) + 1e-10\n",
    "    logits = torch.nn.functional.softmax(logits, dim=2)\n",
    "    #print(logits)\n",
    "    probs = torch.gather(logits, 2, input_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    if \"gpt\" in model_name:  # Scaling\n",
    "        probs = probs * 1e4\n",
    "    #print(probs)\n",
    "#     probs2 = torch.zeros_like(input_ids, dtype=float)\n",
    "#     for batch_ind, logit in enumerate(logits):\n",
    "#         batch_input_ids = input_ids[batch_ind]\n",
    "#         for seq_ind, wid in enumerate(batch_input_ids):\n",
    "#             probs2[batch_ind, seq_ind] = logits[batch_ind, seq_ind, wid]\n",
    "    \n",
    "#     assert torch.all(probs == probs2)\n",
    "    probs = torch.prod(probs, dim=1)\n",
    "    #probs = torch.prod(probs[:, 1:], dim=1)\n",
    "    #probs = probs[:, 0]  # CLSes\n",
    "    #probs = probs[:, 8]  # MASK\n",
    "    #print(probs)\n",
    "    #assert False\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset):\n",
    "    dataset0, dataset1 = eval_dataset\n",
    "    eval_dataloader0 = DataLoader(dataset0, batch_size=args.per_device_eval_batch_size, shuffle=False)\n",
    "    eval_dataloader1 = DataLoader(dataset1, batch_size=args.per_device_eval_batch_size, shuffle=False)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(dataset0)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader0 = tqdm(eval_dataloader0, desc=\"Evaluating\")\n",
    "    eval_dataloader1 = tqdm(eval_dataloader1, desc=\"Evaluating\")\n",
    "    \n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    first_age = []\n",
    "    second_age = []\n",
    "    young_probs = []\n",
    "    old_probs = []\n",
    "    for batch in eval_dataloader0:\n",
    "        model.eval()\n",
    "        for i in range(len(batch[\"answer_id\"])):\n",
    "            if batch[\"choice_list\"][0][i] == \"older\":\n",
    "                batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "        all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "        offset = 1 if \"gpt\" in args.model_name_or_path.lower() else 0\n",
    "        age1 = tokenizer.decode(batch[\"input_ids\"][:, 2 - offset]).split(\" \")\n",
    "        age2 = tokenizer.decode(batch[\"input_ids\"][:, 11 - offset]).split(\" \")\n",
    "        if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"gpt\")):\n",
    "            age1 = age1[1:]\n",
    "            age2 = age2[1:]\n",
    "        \n",
    "        first_age.extend(age1)\n",
    "        second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            young_probs.extend(get_sentence_prob(args.model_name_or_path, batch[\"input_ids\"], logits).tolist())\n",
    "            \n",
    "    for batch in eval_dataloader1:\n",
    "        model.eval()\n",
    "#         for i in range(len(batch[\"answer_id\"])):\n",
    "#             if batch[\"choice_list\"][0][i] == \"older\":\n",
    "#                 batch[\"answer_id\"][i] = -batch[\"answer_id\"][i] + 1  # Flip 1 -> 0, 0 -> 1\n",
    "        \n",
    "#         all_answers.extend(batch[\"answer_id\"].tolist())\n",
    "        \n",
    "        del batch[\"choice_list\"] \n",
    "        for key in batch:\n",
    "            if key != \"answer_id\":\n",
    "                batch[key] = torch.stack(batch[key], dim=-1)\n",
    "\n",
    "            batch[key] = batch[key].cuda()\n",
    "            \n",
    "#         age1 = tokenizer.decode(batch[\"input_ids\"][:, 2]).split(\" \")\n",
    "#         age2 = tokenizer.decode(batch[\"input_ids\"][:, 11]).split(\" \")\n",
    "#         if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\")):\n",
    "#             age1 = age1[1:]\n",
    "#             age2 = age2[1:]\n",
    "        \n",
    "#         first_age.extend(age1)\n",
    "#         second_age.extend(age2)\n",
    "        answer_ids = batch.pop(\"answer_id\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            old_probs.extend(get_sentence_prob(args.model_name_or_path, batch[\"input_ids\"], logits).tolist())\n",
    "            \n",
    "        \n",
    "        # preds = torch.gt(logits[:, MASK_INDEX, OLD_ID], logits[:, MASK_INDEX, YOUNG_ID])\n",
    "        # preds = torch.gt(old_prob, young_prob)\n",
    "        #print(\"---\")\n",
    "        #print(preds)\n",
    "        #print(young_prob)\n",
    "        #print(old_prob)\n",
    "        # all_preds.extend(preds.tolist())\n",
    "    for i in range(len(young_probs)):\n",
    "        all_preds.append(young_probs[i] < old_probs[i])\n",
    "\n",
    "    first_age = [int(age) for age in first_age]\n",
    "    second_age = [int(age) for age in second_age]\n",
    "    return all_answers, all_preds, first_age, second_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "            \n",
    "# \"bert-base-uncased\", \n",
    "# \"bert-large-uncased-whole-word-masking\", \n",
    "# \"roberta-large\",\n",
    "# \"distilbert-base-uncased\", \n",
    "# \"facebook/bart-large\",\n",
    "# \"albert-large-v1\",\n",
    "# \"google/electra-large-discriminator\",\n",
    "# \"gpt2\",\n",
    "# \"t5-large\",\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"facebook/bart-large\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/05/2021 09:48:09: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_train.jsonl\n",
      "05/05/2021 09:48:09: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386bacec24c540dca9e4c2e7f2843826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/05/2021 09:48:09: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74488720efb431290063126ac4cc38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = get_args()\n",
    "transformers.set_seed(args.seed)\n",
    "model = transformers.AutoModelWithLMHead.from_pretrained(args.model_name_or_path).cuda()\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "train_questions, train_choices, train_answer_ids = get_data(\"data/number_comparison_age_compare_masked_train.jsonl\", args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(\"data/number_comparison_age_compare_masked_dev.jsonl\", args.sample_eval, args.num_choices)\n",
    "\n",
    "eval_questions = train_questions + eval_questions\n",
    "eval_choices = train_choices + eval_choices\n",
    "eval_answer_ids = train_answer_ids + eval_answer_ids\n",
    "\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\", \"gpt2\", \"t5\")) else BERTDataset\n",
    "train_dataset = CombinedDataset(AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer, \"younger\"), AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer, \"older\"))\n",
    "eval_dataset = CombinedDataset(AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer, \"younger\"), AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer, \"older\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c8f8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b6e8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/05/2021 09:48:09: ***** Running evaluation  *****\n",
      "05/05/2021 09:48:09:   Num examples = 700\n",
      "05/05/2021 09:48:09:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3867172c7d704464a68f8aa07f4d34bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3973a15f5c594905b07eeeba61ad889a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_answers, all_preds, first_age, second_age = evaluate(args, model, tokenizer, eval_dataset)\n",
    "# correct = [1 if all_answers[i] == all_preds[i] else 0 for i in range(len(all_answers))]\n",
    "# print(np.array(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ef19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(first_age, second_age, c=all_preds, marker=\"s\")\n",
    "plt.title(f\"Age Comparison\\n{args.model_name_or_path}\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Age 1\")\n",
    "plt.ylabel(\"Age 2\")\n",
    "plt.savefig(f\"imgs/{args.model_name_or_path.rsplit('/', 1)[-1]}-ages-double-expanded.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59158570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<s>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85141f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6]],\n",
       "\n",
       "        [[11, 12],\n",
       "         [13, 14],\n",
       "         [15, 16]],\n",
       "\n",
       "        [[21, 22],\n",
       "         [23, 24],\n",
       "         [25, 26]],\n",
       "\n",
       "        [[31, 32],\n",
       "         [33, 34],\n",
       "         [35, 36]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = torch.tensor([[[1, 2], [3, 4], [5, 6]], [[11, 12], [13, 14], [15, 16]], [[21, 22], [23, 24], [25, 26]], [[31, 32], [33, 34], [35, 36]]])\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa6f2f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1],\n",
       "         [ 4],\n",
       "         [ 5]],\n",
       "\n",
       "        [[11],\n",
       "         [13],\n",
       "         [15]],\n",
       "\n",
       "        [[21],\n",
       "         [23],\n",
       "         [25]],\n",
       "\n",
       "        [[31],\n",
       "         [33],\n",
       "         [35]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = torch.tensor([[[0], [1], [0]], [[0], [0], [0]], [[0], [0], [0]], [[0], [0], [0]]])\n",
    "torch.gather(asdf, 2, inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8480604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
