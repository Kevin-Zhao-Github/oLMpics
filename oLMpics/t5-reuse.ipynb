{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d009a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomArguments(transformers.TrainingArguments):\n",
    "    sample_train: int = 0\n",
    "    sample_eval: int = 0\n",
    "    num_choices: int = 0\n",
    "    model_name_or_path: str = \"asdf\"  # this is no longer a TrainingArgument attribute\n",
    "        \n",
    "    # python dataclasses cannot have positional attributes in subclass,\n",
    "    # so give all attributes defaults and then make sure they are changed\n",
    "    def __post_init__(self):\n",
    "        if not (self.sample_train * self.sample_eval * self.num_choices) or \\\n",
    "               self.model_name_or_path == \"asdf\":  # make sure none are still default value\n",
    "            raise TypeError(\"__init__ missing required argument(s)\")\n",
    "\n",
    "def get_args():\n",
    "    \"\"\" Set hyperparameters \"\"\"\n",
    "    args = CustomArguments(\n",
    "        output_dir=\"checkpoint\",\n",
    "        model_name_or_path=\"roberta-base\",\n",
    "        overwrite_output_dir=True,\n",
    "        do_train=False,  # Zero shot\n",
    "        do_eval=True,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=1e-5,  # Should not matter because not training\n",
    "        weight_decay=0.1,\n",
    "        save_total_limit=2,\n",
    "        seed=123,\n",
    "        sample_train=200,\n",
    "        sample_eval=-1,\n",
    "        num_choices=2,\n",
    "    )\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b031c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path, sample, num_choices):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    logger.info(\"Reading QA instances from jsonl dataset at: %s\", file_path)\n",
    "    item_jsons = []\n",
    "    item_ids = []\n",
    "    questions = []\n",
    "    choice_lists = []\n",
    "    answer_ids = []\n",
    "    for line in data_file:\n",
    "        item_jsons.append(json.loads(line.strip()))\n",
    "\n",
    "    if sample != -1:\n",
    "        item_jsons = random.sample(item_jsons, sample)\n",
    "        logger.info(\"Sampling %d examples\", sample)\n",
    "\n",
    "    for item_json in tqdm(item_jsons,total=len(item_jsons)):\n",
    "        item_id = item_json[\"id\"]\n",
    "\n",
    "        question_text = item_json[\"question\"][\"stem\"]\n",
    "\n",
    "        choice_label_to_id = {}\n",
    "        choice_text_list = []\n",
    "        choice_context_list = []\n",
    "        choice_label_list = []\n",
    "        choice_annotations_list = []\n",
    "\n",
    "        any_correct = False\n",
    "        choice_id_correction = 0\n",
    "\n",
    "        for choice_id, choice_item in enumerate(item_json[\"question\"][\"choices\"]):\n",
    "            choice_label = choice_item[\"label\"]\n",
    "            choice_label_to_id[choice_label] = choice_id - choice_id_correction\n",
    "            choice_text = choice_item[\"text\"]\n",
    "\n",
    "            choice_text_list.append(choice_text)\n",
    "            choice_label_list.append(choice_label)\n",
    "\n",
    "            if item_json.get('answerKey') == choice_label:\n",
    "                if any_correct:\n",
    "                    raise ValueError(\"More than one correct answer found for {item_json}!\")\n",
    "                any_correct = True\n",
    "\n",
    "\n",
    "        if not any_correct and 'answerKey' in item_json:\n",
    "            raise ValueError(\"No correct answer found for {item_json}!\")\n",
    "\n",
    "\n",
    "        answer_id = choice_label_to_id.get(item_json.get(\"answerKey\"))\n",
    "        # Pad choices with empty strings if not right number\n",
    "        if len(choice_text_list) != num_choices:\n",
    "            choice_text_list = (choice_text_list + num_choices * [''])[:num_choices]\n",
    "            choice_context_list = (choice_context_list + num_choices * [None])[:num_choices]\n",
    "            if answer_id is not None and answer_id >= num_choices:\n",
    "                logging.warning(f\"Skipping question with more than {num_choices} answers: {item_json}\")\n",
    "                continue\n",
    "\n",
    "        item_ids.append(item_id)\n",
    "        questions.append(question_text)\n",
    "        choice_lists.append(choice_text_list)\n",
    "        answer_ids.append(answer_id)\n",
    "\n",
    "    data_file.close()\n",
    "    return questions, choice_lists, answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer):\n",
    "        out = tokenizer(questions, max_length=25, padding=\"max_length\")\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.token_type_ids = out[\"token_type_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"token_type_ids\": self.token_type_ids[i],\n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }\n",
    "    \n",
    "\n",
    "class RoBERTaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, questions, choices, answer_ids, tokenizer, padding=True):\n",
    "        questions = [question.replace('[MASK]', tokenizer.mask_token) for question in questions]\n",
    "        if padding:\n",
    "            out = tokenizer(questions, max_length=25, padding=\"max_length\")\n",
    "        else:\n",
    "            out = tokenizer(questions)\n",
    "        self.input_ids = out[\"input_ids\"]\n",
    "        self.attention_mask = out[\"attention_mask\"]\n",
    "        self.questions = questions\n",
    "        self.choices = choices\n",
    "        self.answer_ids = answer_ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[i], \n",
    "            \"attention_mask\": self.attention_mask[i], \n",
    "            \"choice_list\": self.choices[i], \n",
    "            \"answer_id\": self.answer_ids[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f035fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_dataset, num_heads_disabled=None):\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_device_eval_batch_size)\n",
    "\n",
    "    logger.info(f\"***** Running evaluation  *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_dataloader = tqdm(eval_dataloader, desc=\"Evaluating\")\n",
    "    \n",
    "    print(tokenizer.mask_token)\n",
    "    MASK_ID = tokenizer.encode(tokenizer.mask_token, add_special_tokens=False)\n",
    "    assert len(MASK_ID) == 1\n",
    "    MASK_ID = MASK_ID[0]\n",
    "    if \"t5\" in args.model_name_or_path.lower():\n",
    "        DECODER_IDS = tokenizer(\"<pad> <extra_id_0>\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "        DECODER_IDS = DECODER_IDS.input_ids#.cuda() \n",
    "        \n",
    "    all_answers = []\n",
    "    all_preds = []    \n",
    "    \n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        \n",
    "        # batch[\"choice_list\"] is [num_choices, batch_size]\n",
    "        for i in range(len(batch[\"choice_list\"][0])):\n",
    "            all_answers.append(batch[\"choice_list\"][batch[\"answer_id\"][i]][i])\n",
    "        \n",
    "        choice_lists = batch.pop(\"choice_list\")\n",
    "        batch_len = len(batch[\"answer_id\"])\n",
    "        del batch[\"answer_id\"] \n",
    "        for key in batch:\n",
    "            batch[key] = torch.stack(batch[key], dim=-1)#.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            assert \"t5\" in args.model_name_or_path.lower()\n",
    "            BATCH_DECODER_IDS = DECODER_IDS.repeat(batch_len, 1)\n",
    "            outputs = model(input_ids=batch[\"input_ids\"], decoder_input_ids=BATCH_DECODER_IDS)\n",
    "                \n",
    "            logits = outputs.logits\n",
    "            choice_ids = []\n",
    "            \n",
    "            for i, logit in enumerate(logits):  # Assuming all are single tokens\n",
    "                choice_ids = torch.tensor([tokenizer.encode(\" \" + choice_lists[j][i], add_special_tokens=False)[0] for j in range(len(choice_lists))])\n",
    "                if \"t5\" in args.model_name_or_path.lower():\n",
    "                    probs = logit[1].index_select(0, choice_ids)#.cuda()\n",
    "                else:\n",
    "                    MASK_INDEX = batch[\"input_ids\"][i].tolist().index(MASK_ID) \n",
    "                    probs = logit[MASK_INDEX].index_select(0, choice_ids)#.cuda())\n",
    "                \n",
    "                max_ind = torch.argmax(probs)\n",
    "                all_preds.append(choice_lists[max_ind][i])\n",
    "\n",
    "    return all_answers, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4dc1b65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "'''\n",
    "\"bert-base-uncased\"\n",
    "\"distilbert-base-uncased\"\n",
    "\"bert-large-uncased\"\n",
    "\"bert-large-uncased-whole-word-masking\" \n",
    "\"roberta-large\"\n",
    "\"facebook/bart-large\"\n",
    "\"t5-large\"\n",
    "\"albert-large-v1\"\n",
    "'''\n",
    "\n",
    "# args.model_name_or_path = \"bert-large-uncased-whole-word-masking\"\n",
    "# args.model_name_or_path = \"roberta-large\"\n",
    "args.model_name_or_path = \"t5-large\"\n",
    "transformers.set_seed(args.seed)\n",
    "if \"t5\" in args.model_name_or_path.lower():\n",
    "    model = transformers.T5ForConditionalGeneration.from_pretrained(args.model_name_or_path)#.cuda()\n",
    "#     args.per_device_eval_batch_size = 1\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.mask_token = \"<extra_id_0>\"\n",
    "elif \"gpt\" in args.model_name_or_path.lower():\n",
    "    model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path)#.cuda()\n",
    "    args.per_device_eval_batch_size = 1\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.mask_token = \"[MASK]\"\n",
    "else:\n",
    "    model = transformers.AutoModelForMaskedLM.from_pretrained(args.model_name_or_path)#.cuda()\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca81746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/07/2021 21:52:18: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n",
      "11/07/2021 21:52:18: Sampling 200 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0177b5e322b4586b843aeea3088edc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/07/2021 21:52:18: Reading QA instances from jsonl dataset at: data/number_comparison_age_compare_masked_dev.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56a966cf3bc44ccab1e326745cc8db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "\"data/number_comparison_age_compare_masked_dev.jsonl\"\n",
    "\"data/coffee_cats_quantifiers_dev.jsonl\"\n",
    "\"data/size_comparison_dev.jsonl\"\n",
    "\"data/antonym_synonym_negation_dev.jsonl\"\n",
    "\"data/hypernym_conjunction_dev.jsonl\"\n",
    "'''\n",
    "train_path = \"data/number_comparison_age_compare_masked_dev.jsonl\"\n",
    "# train_path = \"data/hypernym_conjunction_dev.jsonl\"\n",
    "# train_path = \"data/number_comparison_age_compare_masked_train.jsonl\"\n",
    "# train_path = \"data/size_comparison_dev.jsonl\"\n",
    "# train_path = \"data/coffee_cats_quantifiers_dev.jsonl\"\n",
    "args.num_choices = 2\n",
    "eval_path = train_path #\"data/coffee_cats_quantifiers_dev.jsonl\"\n",
    "train_questions, train_choices, train_answer_ids = get_data(train_path, args.sample_train, args.num_choices)\n",
    "eval_questions, eval_choices, eval_answer_ids = get_data(eval_path, args.sample_eval, args.num_choices)\n",
    "AgeDataset = RoBERTaDataset if any(prefix in args.model_name_or_path.lower() for prefix in (\"roberta\", \"bart\", \"distil\", \"electra\", \"t5\")) else BERTDataset\n",
    "train_dataset = AgeDataset(train_questions, train_choices, train_answer_ids, tokenizer, padding=False)\n",
    "eval_dataset = AgeDataset(eval_questions, eval_choices, eval_answer_ids, tokenizer, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e8937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/07/2021 21:55:29: ***** Running evaluation  *****\n",
      "11/07/2021 21:55:29:   Num examples = 500\n",
      "11/07/2021 21:55:29:   Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add075570be644db87d07d8fc278bca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0>\n"
     ]
    }
   ],
   "source": [
    "all_answers, all_preds = evaluate(args, model, tokenizer, eval_dataset)\n",
    "print((np.array(all_answers) == np.array(all_preds)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290412b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
